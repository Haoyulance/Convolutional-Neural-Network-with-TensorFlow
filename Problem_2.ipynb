{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Getting familiar with TensorFlow\n",
    "\n",
    "*TensorFlow* is one of the most popular deep learning framework developed by Google. If you are new to TensorFlow, please read and play with the sample in [Getting started with TensorFlow](https://www.tensorflow.org/get_started/get_started) to get started.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 1, you implemented a fully connected network from scratch on your own. Very tedious to do it all by yourself, right? Well, we actually feel the same thing, that's why we are using tools instead of doing everything from scratch. For this part of the assignment, we will familiarize you with a widely-used deep learning framework developed by Google, TensorFlow and walk you through convolutional neural networks and show how to train them.\n",
    "* <b>Provided Codes:</b> We provide the Template class for a simple CNN model as BaseModel, predefined skeletons for conv2d() and max_pool(), as well as the dataset preprocessing parts.\n",
    "* <b>TODOs:</b> You are asked to implement the BaseModel following the detailed instructions and design your own model in YourModel to achieve a reasonably good performance for classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.datasets import CIFAR10_tf\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"TensorFlow Version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test matplotlib\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(x, np.maximum(0, x), label='relu')\n",
    "plt.plot(x, 1/(1 + np.exp(-x)), label='sigmoid')\n",
    "plt.plot(x, (1 - np.exp(-2 * x))/(1 + np.exp(-2 * x)), label='tanh')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.title(\"Activation functions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n",
      "2.000000 * 3.000000 = 6.000000\n"
     ]
    }
   ],
   "source": [
    "# Test tensorflow\n",
    "print('TensorFlow version: ' + tf.__version__)\n",
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = a * b\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run([a, b, c])\n",
    "print('%f * %f = %f' % (result[0], result[1], result[2]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Download [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and load the dataset. In this assignment, we will use the standard 50,000 images for training and 10,000 images for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_training = 49000\n",
    "num_validation = 50000 - num_training\n",
    "num_test = 10000\n",
    "\n",
    "data = CIFAR10_tf(num_training=num_training,\n",
    "                  num_validation=num_validation,\n",
    "                  num_test=num_test)\n",
    "\n",
    "# Load cifar-10 data\n",
    "X_train, Y_train = data['data_train'], data['labels_train']\n",
    "X_val, Y_val = data['data_val'], data['labels_val']\n",
    "X_test, Y_test = data['data_test'], data['labels_test']\n",
    "\n",
    "# Check the shape of the dataset\n",
    "assert X_train.shape == (num_training, 32, 32, 3)\n",
    "assert Y_train.shape == (num_training, )\n",
    "assert X_val.shape == (num_validation, 32, 32, 3)\n",
    "assert Y_val.shape == (num_validation, )\n",
    "assert X_test.shape == (num_test, 32, 32, 3)\n",
    "assert Y_test.shape == (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-1\n",
    "\n",
    "Using the code provided, implement a neural network architecture with an optimization routine according to the specification provided below.\n",
    "\n",
    "**Model:**\n",
    "- Input image with the size 32x32x3\n",
    "- 7x7 convolutional layer with 32 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- Flatten layer (8x8x64 -> 4096)\n",
    "- Fully-connected layer with 384 output units (4096 -> 384)\n",
    "- ReLU activation layer\n",
    "- Fully-connected layer with 10 output units (384 -> 10)\n",
    "- Output logits (10)\n",
    "\n",
    "**Optimizer:**\n",
    "- Adam optimizer\n",
    "\n",
    "**Learning rate:**\n",
    "- Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "- Use 'tf.train.exponential_decay' and 'tf.train.AdamOptimizer'\n",
    "\n",
    "**Loss:**\n",
    "- Softmax cross entropy loss\n",
    "- Use 'tf.nn.softmax_cross_entropy_with_logits'\n",
    "\n",
    "\n",
    "Your model **should** achieve about 60% accuracy on validation set in 5 epochs using provided evaluation code.\n",
    "\n",
    "You can modify the template code as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pooling and conv layers\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "    \n",
    "    # w is the filter\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Complete the following functions                                    #\n",
    "#############################################################################\n",
    "def flatten(input):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.contrib.layers.flatten(input)\n",
    "\n",
    "def fc(input, num_output):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "        - num_output: int, the output dimension\n",
    "    \"\"\"\n",
    "    shape = np.shape(input)\n",
    "    #b = tf.get_variable( [*shape[-1], num_output], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.contrib.layers.fully_connected(input, num_output, activation_fn=None)\n",
    "\n",
    "def norm(input, is_training):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "        - is_training: boolean, if during training or not\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.layers.batch_normalization(input, training=is_training)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 128\n",
    "        self.log_step = 50\n",
    "        self._build_model()\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.pool2 = max_pool(self.relu2, 3, 2)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = flatten(self.pool2)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc3 = fc(self.flat, 384)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.relu3.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc4 = fc(self.relu3, 10)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "            \n",
    "        # Return the last layer\n",
    "        return self.fc4\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        \n",
    "#         self.fc3 = tf.placeholder(tf.float32, [None, 4096, 384])\n",
    "#         self.fc4 = tf.placeholder(tf.float32, [None, 384, 10])\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        global_step = tf.Variable(500, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(5e-4, 500, 500, 0.96)\n",
    "        #self.train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss_op, global_step=global_step)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss_op)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        #self.loss_op = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits) #this self.y should be one-hot\n",
    "        \n",
    "        #self.loss_op = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "        \n",
    "        self.loss_op = tf.losses.softmax_cross_entropy(labels, logits)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1) # the second parameter is the axis\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X: X_, self.Y: Y_}\n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                   #print(loss)\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            \n",
    "        #############################################################################\n",
    "        # TODO: Plot training curve                                                 #\n",
    "        #############################################################################\n",
    "        # Graph 1. X: epoch, Y: training loss\n",
    "        losses = losses[1::num_training // self.batch_size] # sparse the curve a bit\n",
    "        plt.plot(losses, '-o')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('training loss')\n",
    "        plt.gcf().set_size_inches(11, 4)\n",
    "        plt.show()\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "            \n",
    "            #############################################################################\n",
    "            # TODO: You can change feed data as you want                                #\n",
    "            #############################################################################\n",
    "            feed_dict = {self.X: X_, self.Y: Y_}\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "flat layer: (?, 4096)\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 12.818, accuracy = 0.094\n",
      "iteration (50): loss = 2.094, accuracy = 0.188\n",
      "iteration (100): loss = 1.962, accuracy = 0.273\n",
      "iteration (150): loss = 1.762, accuracy = 0.320\n",
      "iteration (200): loss = 1.838, accuracy = 0.336\n",
      "iteration (250): loss = 1.867, accuracy = 0.375\n",
      "iteration (300): loss = 1.526, accuracy = 0.430\n",
      "iteration (350): loss = 1.604, accuracy = 0.414\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.496\n",
      "train for epoch 1\n",
      "iteration (400): loss = 1.550, accuracy = 0.461\n",
      "iteration (450): loss = 1.486, accuracy = 0.430\n",
      "iteration (500): loss = 1.371, accuracy = 0.508\n",
      "iteration (550): loss = 1.262, accuracy = 0.602\n",
      "iteration (600): loss = 1.372, accuracy = 0.570\n",
      "iteration (650): loss = 1.473, accuracy = 0.477\n",
      "iteration (700): loss = 1.249, accuracy = 0.539\n",
      "iteration (750): loss = 1.113, accuracy = 0.609\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.571\n",
      "train for epoch 2\n",
      "iteration (800): loss = 1.149, accuracy = 0.555\n",
      "iteration (850): loss = 1.367, accuracy = 0.508\n",
      "iteration (900): loss = 1.042, accuracy = 0.641\n",
      "iteration (950): loss = 1.081, accuracy = 0.625\n",
      "iteration (1000): loss = 1.173, accuracy = 0.539\n",
      "iteration (1050): loss = 1.024, accuracy = 0.633\n",
      "iteration (1100): loss = 1.085, accuracy = 0.648\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.616\n",
      "train for epoch 3\n",
      "iteration (1150): loss = 1.132, accuracy = 0.641\n",
      "iteration (1200): loss = 1.087, accuracy = 0.641\n",
      "iteration (1250): loss = 1.056, accuracy = 0.672\n",
      "iteration (1300): loss = 1.272, accuracy = 0.570\n",
      "iteration (1350): loss = 1.002, accuracy = 0.625\n",
      "iteration (1400): loss = 0.905, accuracy = 0.688\n",
      "iteration (1450): loss = 1.016, accuracy = 0.594\n",
      "iteration (1500): loss = 0.854, accuracy = 0.672\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.622\n",
      "train for epoch 4\n",
      "iteration (1550): loss = 0.910, accuracy = 0.703\n",
      "iteration (1600): loss = 0.991, accuracy = 0.695\n",
      "iteration (1650): loss = 1.157, accuracy = 0.578\n",
      "iteration (1700): loss = 0.800, accuracy = 0.734\n",
      "iteration (1750): loss = 1.028, accuracy = 0.680\n",
      "iteration (1800): loss = 0.918, accuracy = 0.664\n",
      "iteration (1850): loss = 1.014, accuracy = 0.641\n",
      "iteration (1900): loss = 0.940, accuracy = 0.680\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.610\n",
      "Model saved in lib/tf_models/problem2/csci-599_sample.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train our sample model\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = BaseModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_sample.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-2\n",
    "\n",
    "Implement your own model. \n",
    "\n",
    "You can modify the template code as you want and you can use GPU for fast training.  \n",
    "For GPU usage, simply change the following line of the training block:  \n",
    "from `with tf.device('/cpu:0')` to `with tf.device('/GPU:0')`  \n",
    "and you can set your desired device number  \n",
    "\n",
    "These are the techniques that you can try:\n",
    "- Data preprocessing\n",
    "- Data augmentation\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "- More convolutional layers\n",
    "- More training epochs\n",
    "- Learning rate decay\n",
    "- Any other models and techniqes\n",
    "\n",
    "Your model should achieve >= 70% accuracy on the test set of CIFAR-10.\n",
    "\n",
    "If the accuracy of the model reaches to 80%, you will get 5 extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(input, is_training, keep_prob):\n",
    "    if is_training is not None:\n",
    "        return tf.nn.dropout(input, keep_prob)\n",
    "    else:\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 20\n",
    "        self.batch_size = 64\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Your model  ' + '-' * 5)\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Implement you own model here                                        #\n",
    "        #############################################################################\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)\n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "          \n",
    "        with tf.variable_scope('conv2'):\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.pool2 = max_pool(self.relu2, 3, 2)\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('conv3'):\n",
    "            self.conv3 = conv2d(self.pool2, 3, 1, 128)\n",
    "            self.relu3 = tf.nn.relu(self.conv3)\n",
    "            self.pool3 = max_pool(self.relu3, 3, 2)\n",
    "            print('conv3 layer: ' + str(self.pool3.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('conv4'):\n",
    "            self.conv4 = conv2d(self.pool3, 3, 1, 256)\n",
    "            self.relu4 = tf.nn.relu(self.conv4)\n",
    "            self.pool4 = max_pool(self.relu4, 3, 2)\n",
    "            print('conv4 layer: ' + str(self.pool4.get_shape()))\n",
    "        \n",
    "#         with tf.variable_scope('conv5'):\n",
    "#             self.conv5 = conv2d(self.pool4, 3, 1, 256)\n",
    "#             self.relu5 = tf.nn.relu(self.conv5)\n",
    "#             self.pool5 = max_pool(self.relu5, 3, 2)\n",
    "#             print('conv5 layer: ' + str(self.pool5.get_shape()))\n",
    "        \n",
    "#         with tf.variable_scope('conv6'):\n",
    "#             self.conv6 = conv2d(self.pool5, 2, 1, 256)\n",
    "#             self.relu6 = tf.nn.relu(self.conv6)\n",
    "#             self.pool6 = max_pool(self.relu6, 3, 2)\n",
    "#             print('conv6 layer: ' + str(self.pool6.get_shape()))\n",
    "        \n",
    "        self.flat = flatten(self.pool4)     \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('fc3'):\n",
    "            self.dropout1 = dropout(self.flat, self.is_training, self.keep_prob)\n",
    "            self.fc3 = fc(self.dropout1, 100)\n",
    "\n",
    "            self.relu8 = tf.nn.relu(self.fc3)\n",
    "            print('fc3 layer: ' + str(self.relu8.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc4'):\n",
    "            self.dropout2 = dropout(self.relu8, self.is_training, self.keep_prob)\n",
    "            self.fc4 = fc(self.dropout2, 100)\n",
    "\n",
    "            self.relu9 = tf.nn.relu(self.fc4)\n",
    "            print('fc4 layer: ' + str(self.relu9.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc5'):\n",
    "            self.fc5 = fc(self.relu9, 10)\n",
    "            print('fc5 layer: ' + str(self.fc5.get_shape()))\n",
    "        \n",
    "        return self.fc5\n",
    "    \n",
    "    def _build_optimizer(self):\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(5e-4, global_step, 500, 0.8)\n",
    "        #self.train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss_op, global_step=global_step)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss_op, global_step=global_step)\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    \n",
    "    \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                \n",
    "                feed_dict = {self.X: X_, self.Y: Y_, self.is_training: False, self.keep_prob: 0.8}\n",
    "                \n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                   #print(loss)\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            \n",
    "       \n",
    "        # Graph 1. X: epoch, Y: training loss\n",
    "        losses = losses[1::num_training // self.batch_size] # sparse the curve a bit\n",
    "        plt.plot(losses, '-o')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('training loss')\n",
    "        plt.gcf().set_size_inches(11, 4)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "            \n",
    "            feed_dict = {self.X: X_, self.Y: Y_, self.is_training: True, self.keep_prob: 1}\n",
    "            \n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "conv3 layer: (?, 4, 4, 128)\n",
      "conv4 layer: (?, 2, 2, 256)\n",
      "flat layer: (?, 1024)\n",
      "fc3 layer: (?, 100)\n",
      "fc4 layer: (?, 100)\n",
      "fc5 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 3.563, accuracy = 0.266\n",
      "iteration (50): loss = 1.988, accuracy = 0.281\n",
      "iteration (100): loss = 2.012, accuracy = 0.312\n",
      "iteration (150): loss = 1.872, accuracy = 0.312\n",
      "iteration (200): loss = 1.756, accuracy = 0.375\n",
      "iteration (250): loss = 1.674, accuracy = 0.391\n",
      "iteration (300): loss = 1.599, accuracy = 0.438\n",
      "iteration (350): loss = 1.573, accuracy = 0.406\n",
      "iteration (400): loss = 1.463, accuracy = 0.547\n",
      "iteration (450): loss = 1.304, accuracy = 0.578\n",
      "iteration (500): loss = 1.555, accuracy = 0.516\n",
      "iteration (550): loss = 1.430, accuracy = 0.500\n",
      "iteration (600): loss = 1.477, accuracy = 0.438\n",
      "iteration (650): loss = 1.375, accuracy = 0.422\n",
      "iteration (700): loss = 1.554, accuracy = 0.391\n",
      "iteration (750): loss = 1.670, accuracy = 0.422\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.516\n",
      "train for epoch 1\n",
      "iteration (800): loss = 1.390, accuracy = 0.547\n",
      "iteration (850): loss = 1.468, accuracy = 0.500\n",
      "iteration (900): loss = 1.206, accuracy = 0.531\n",
      "iteration (950): loss = 1.425, accuracy = 0.578\n",
      "iteration (1000): loss = 1.286, accuracy = 0.594\n",
      "iteration (1050): loss = 1.367, accuracy = 0.484\n",
      "iteration (1100): loss = 1.409, accuracy = 0.484\n",
      "iteration (1150): loss = 0.931, accuracy = 0.625\n",
      "iteration (1200): loss = 1.200, accuracy = 0.562\n",
      "iteration (1250): loss = 0.941, accuracy = 0.625\n",
      "iteration (1300): loss = 1.138, accuracy = 0.609\n",
      "iteration (1350): loss = 1.314, accuracy = 0.547\n",
      "iteration (1400): loss = 0.965, accuracy = 0.656\n",
      "iteration (1450): loss = 1.188, accuracy = 0.594\n",
      "iteration (1500): loss = 1.166, accuracy = 0.594\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.625\n",
      "train for epoch 2\n",
      "iteration (1550): loss = 1.263, accuracy = 0.594\n",
      "iteration (1600): loss = 1.168, accuracy = 0.516\n",
      "iteration (1650): loss = 1.311, accuracy = 0.547\n",
      "iteration (1700): loss = 1.253, accuracy = 0.578\n",
      "iteration (1750): loss = 1.066, accuracy = 0.500\n",
      "iteration (1800): loss = 1.098, accuracy = 0.609\n",
      "iteration (1850): loss = 1.157, accuracy = 0.641\n",
      "iteration (1900): loss = 0.846, accuracy = 0.672\n",
      "iteration (1950): loss = 1.202, accuracy = 0.625\n",
      "iteration (2000): loss = 1.161, accuracy = 0.625\n",
      "iteration (2050): loss = 0.916, accuracy = 0.688\n",
      "iteration (2100): loss = 0.744, accuracy = 0.750\n",
      "iteration (2150): loss = 0.897, accuracy = 0.734\n",
      "iteration (2200): loss = 0.948, accuracy = 0.688\n",
      "iteration (2250): loss = 0.800, accuracy = 0.703\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.678\n",
      "train for epoch 3\n",
      "iteration (2300): loss = 1.038, accuracy = 0.562\n",
      "iteration (2350): loss = 1.032, accuracy = 0.672\n",
      "iteration (2400): loss = 0.766, accuracy = 0.719\n",
      "iteration (2450): loss = 0.833, accuracy = 0.672\n",
      "iteration (2500): loss = 0.890, accuracy = 0.656\n",
      "iteration (2550): loss = 0.921, accuracy = 0.641\n",
      "iteration (2600): loss = 1.163, accuracy = 0.609\n",
      "iteration (2650): loss = 0.778, accuracy = 0.750\n",
      "iteration (2700): loss = 0.884, accuracy = 0.750\n",
      "iteration (2750): loss = 1.035, accuracy = 0.688\n",
      "iteration (2800): loss = 0.872, accuracy = 0.672\n",
      "iteration (2850): loss = 0.701, accuracy = 0.719\n",
      "iteration (2900): loss = 0.778, accuracy = 0.797\n",
      "iteration (2950): loss = 0.856, accuracy = 0.688\n",
      "iteration (3000): loss = 0.529, accuracy = 0.875\n",
      "iteration (3050): loss = 0.826, accuracy = 0.703\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.686\n",
      "train for epoch 4\n",
      "iteration (3100): loss = 0.640, accuracy = 0.766\n",
      "iteration (3150): loss = 0.686, accuracy = 0.781\n",
      "iteration (3200): loss = 1.015, accuracy = 0.609\n",
      "iteration (3250): loss = 0.850, accuracy = 0.734\n",
      "iteration (3300): loss = 0.723, accuracy = 0.750\n",
      "iteration (3350): loss = 0.862, accuracy = 0.766\n",
      "iteration (3400): loss = 0.819, accuracy = 0.719\n",
      "iteration (3450): loss = 0.731, accuracy = 0.734\n",
      "iteration (3500): loss = 0.672, accuracy = 0.766\n",
      "iteration (3550): loss = 0.916, accuracy = 0.625\n",
      "iteration (3600): loss = 0.690, accuracy = 0.734\n",
      "iteration (3650): loss = 0.807, accuracy = 0.703\n",
      "iteration (3700): loss = 0.862, accuracy = 0.703\n",
      "iteration (3750): loss = 0.637, accuracy = 0.844\n",
      "iteration (3800): loss = 0.646, accuracy = 0.703\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.726\n",
      "train for epoch 5\n",
      "iteration (3850): loss = 0.669, accuracy = 0.766\n",
      "iteration (3900): loss = 0.824, accuracy = 0.750\n",
      "iteration (3950): loss = 0.654, accuracy = 0.797\n",
      "iteration (4000): loss = 0.607, accuracy = 0.812\n",
      "iteration (4050): loss = 0.658, accuracy = 0.766\n",
      "iteration (4100): loss = 0.600, accuracy = 0.781\n",
      "iteration (4150): loss = 0.649, accuracy = 0.766\n",
      "iteration (4200): loss = 0.639, accuracy = 0.734\n",
      "iteration (4250): loss = 0.725, accuracy = 0.750\n",
      "iteration (4300): loss = 0.680, accuracy = 0.750\n",
      "iteration (4350): loss = 0.941, accuracy = 0.672\n",
      "iteration (4400): loss = 0.560, accuracy = 0.766\n",
      "iteration (4450): loss = 0.595, accuracy = 0.734\n",
      "iteration (4500): loss = 0.925, accuracy = 0.656\n",
      "iteration (4550): loss = 0.659, accuracy = 0.734\n",
      "validation for epoch 5\n",
      "-  epoch 5: validation accuracy = 0.743\n",
      "train for epoch 6\n",
      "iteration (4600): loss = 0.947, accuracy = 0.719\n",
      "iteration (4650): loss = 0.749, accuracy = 0.719\n",
      "iteration (4700): loss = 1.050, accuracy = 0.641\n",
      "iteration (4750): loss = 0.736, accuracy = 0.781\n",
      "iteration (4800): loss = 0.494, accuracy = 0.844\n",
      "iteration (4850): loss = 0.607, accuracy = 0.750\n",
      "iteration (4900): loss = 0.788, accuracy = 0.734\n",
      "iteration (4950): loss = 0.705, accuracy = 0.781\n",
      "iteration (5000): loss = 0.851, accuracy = 0.750\n",
      "iteration (5050): loss = 0.565, accuracy = 0.797\n",
      "iteration (5100): loss = 0.703, accuracy = 0.766\n",
      "iteration (5150): loss = 0.622, accuracy = 0.797\n",
      "iteration (5200): loss = 0.719, accuracy = 0.766\n",
      "iteration (5250): loss = 0.411, accuracy = 0.859\n",
      "iteration (5300): loss = 0.539, accuracy = 0.781\n",
      "iteration (5350): loss = 0.545, accuracy = 0.828\n",
      "validation for epoch 6\n",
      "-  epoch 6: validation accuracy = 0.748\n",
      "train for epoch 7\n",
      "iteration (5400): loss = 0.507, accuracy = 0.828\n",
      "iteration (5450): loss = 0.625, accuracy = 0.781\n",
      "iteration (5500): loss = 0.577, accuracy = 0.812\n",
      "iteration (5550): loss = 0.751, accuracy = 0.703\n",
      "iteration (5600): loss = 0.879, accuracy = 0.703\n",
      "iteration (5650): loss = 0.499, accuracy = 0.922\n",
      "iteration (5700): loss = 0.730, accuracy = 0.719\n",
      "iteration (5750): loss = 0.635, accuracy = 0.797\n",
      "iteration (5800): loss = 0.637, accuracy = 0.828\n",
      "iteration (5850): loss = 0.614, accuracy = 0.766\n",
      "iteration (5900): loss = 0.433, accuracy = 0.875\n",
      "iteration (5950): loss = 0.550, accuracy = 0.734\n",
      "iteration (6000): loss = 0.568, accuracy = 0.828\n",
      "iteration (6050): loss = 0.680, accuracy = 0.766\n",
      "iteration (6100): loss = 0.705, accuracy = 0.734\n",
      "validation for epoch 7\n",
      "-  epoch 7: validation accuracy = 0.750\n",
      "train for epoch 8\n",
      "iteration (6150): loss = 0.739, accuracy = 0.734\n",
      "iteration (6200): loss = 0.491, accuracy = 0.844\n",
      "iteration (6250): loss = 0.558, accuracy = 0.797\n",
      "iteration (6300): loss = 0.654, accuracy = 0.703\n",
      "iteration (6350): loss = 0.386, accuracy = 0.906\n",
      "iteration (6400): loss = 0.437, accuracy = 0.859\n",
      "iteration (6450): loss = 0.443, accuracy = 0.844\n",
      "iteration (6500): loss = 0.568, accuracy = 0.797\n",
      "iteration (6550): loss = 0.608, accuracy = 0.812\n",
      "iteration (6600): loss = 0.719, accuracy = 0.719\n",
      "iteration (6650): loss = 0.700, accuracy = 0.750\n",
      "iteration (6700): loss = 0.761, accuracy = 0.766\n",
      "iteration (6750): loss = 0.653, accuracy = 0.750\n",
      "iteration (6800): loss = 0.635, accuracy = 0.766\n",
      "iteration (6850): loss = 0.348, accuracy = 0.906\n",
      "validation for epoch 8\n",
      "-  epoch 8: validation accuracy = 0.741\n",
      "train for epoch 9\n",
      "iteration (6900): loss = 0.437, accuracy = 0.844\n",
      "iteration (6950): loss = 0.452, accuracy = 0.828\n",
      "iteration (7000): loss = 0.835, accuracy = 0.719\n",
      "iteration (7050): loss = 0.769, accuracy = 0.797\n",
      "iteration (7100): loss = 0.639, accuracy = 0.750\n",
      "iteration (7150): loss = 0.469, accuracy = 0.812\n",
      "iteration (7200): loss = 0.581, accuracy = 0.781\n",
      "iteration (7250): loss = 0.654, accuracy = 0.719\n",
      "iteration (7300): loss = 0.537, accuracy = 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration (7350): loss = 0.444, accuracy = 0.859\n",
      "iteration (7400): loss = 0.588, accuracy = 0.766\n",
      "iteration (7450): loss = 0.549, accuracy = 0.750\n",
      "iteration (7500): loss = 0.505, accuracy = 0.797\n",
      "iteration (7550): loss = 0.565, accuracy = 0.797\n",
      "iteration (7600): loss = 0.455, accuracy = 0.875\n",
      "validation for epoch 9\n",
      "-  epoch 9: validation accuracy = 0.742\n",
      "train for epoch 10\n",
      "iteration (7650): loss = 0.522, accuracy = 0.797\n",
      "iteration (7700): loss = 0.504, accuracy = 0.844\n",
      "iteration (7750): loss = 0.593, accuracy = 0.797\n",
      "iteration (7800): loss = 0.325, accuracy = 0.906\n",
      "iteration (7850): loss = 0.525, accuracy = 0.875\n",
      "iteration (7900): loss = 0.523, accuracy = 0.797\n",
      "iteration (7950): loss = 0.623, accuracy = 0.766\n",
      "iteration (8000): loss = 0.369, accuracy = 0.875\n",
      "iteration (8050): loss = 0.544, accuracy = 0.797\n",
      "iteration (8100): loss = 0.420, accuracy = 0.812\n",
      "iteration (8150): loss = 0.604, accuracy = 0.797\n",
      "iteration (8200): loss = 0.436, accuracy = 0.875\n",
      "iteration (8250): loss = 0.516, accuracy = 0.828\n",
      "iteration (8300): loss = 0.392, accuracy = 0.875\n",
      "iteration (8350): loss = 0.685, accuracy = 0.766\n",
      "iteration (8400): loss = 0.620, accuracy = 0.797\n",
      "validation for epoch 10\n",
      "-  epoch 10: validation accuracy = 0.744\n",
      "train for epoch 11\n",
      "iteration (8450): loss = 0.420, accuracy = 0.812\n",
      "iteration (8500): loss = 0.510, accuracy = 0.812\n",
      "iteration (8550): loss = 0.475, accuracy = 0.812\n",
      "iteration (8600): loss = 0.589, accuracy = 0.781\n",
      "iteration (8650): loss = 0.501, accuracy = 0.891\n",
      "iteration (8700): loss = 0.545, accuracy = 0.812\n",
      "iteration (8750): loss = 0.512, accuracy = 0.812\n",
      "iteration (8800): loss = 0.337, accuracy = 0.859\n",
      "iteration (8850): loss = 0.473, accuracy = 0.891\n",
      "iteration (8900): loss = 0.346, accuracy = 0.844\n",
      "iteration (8950): loss = 0.410, accuracy = 0.844\n",
      "iteration (9000): loss = 0.593, accuracy = 0.797\n",
      "iteration (9050): loss = 0.461, accuracy = 0.766\n",
      "iteration (9100): loss = 0.483, accuracy = 0.812\n",
      "iteration (9150): loss = 0.551, accuracy = 0.781\n",
      "validation for epoch 11\n",
      "-  epoch 11: validation accuracy = 0.750\n",
      "train for epoch 12\n",
      "iteration (9200): loss = 0.500, accuracy = 0.891\n",
      "iteration (9250): loss = 0.701, accuracy = 0.781\n",
      "iteration (9300): loss = 0.587, accuracy = 0.797\n",
      "iteration (9350): loss = 0.619, accuracy = 0.766\n",
      "iteration (9400): loss = 0.449, accuracy = 0.844\n",
      "iteration (9450): loss = 0.545, accuracy = 0.812\n",
      "iteration (9500): loss = 0.635, accuracy = 0.766\n",
      "iteration (9550): loss = 0.410, accuracy = 0.859\n",
      "iteration (9600): loss = 0.644, accuracy = 0.750\n",
      "iteration (9650): loss = 0.430, accuracy = 0.828\n",
      "iteration (9700): loss = 0.454, accuracy = 0.875\n",
      "iteration (9750): loss = 0.454, accuracy = 0.875\n",
      "iteration (9800): loss = 0.516, accuracy = 0.844\n",
      "iteration (9850): loss = 0.546, accuracy = 0.844\n",
      "iteration (9900): loss = 0.344, accuracy = 0.906\n",
      "validation for epoch 12\n",
      "-  epoch 12: validation accuracy = 0.749\n",
      "train for epoch 13\n",
      "iteration (9950): loss = 0.658, accuracy = 0.781\n",
      "iteration (10000): loss = 0.505, accuracy = 0.812\n",
      "iteration (10050): loss = 0.379, accuracy = 0.891\n",
      "iteration (10100): loss = 0.372, accuracy = 0.891\n",
      "iteration (10150): loss = 0.417, accuracy = 0.828\n",
      "iteration (10200): loss = 0.470, accuracy = 0.828\n",
      "iteration (10250): loss = 0.548, accuracy = 0.797\n",
      "iteration (10300): loss = 0.422, accuracy = 0.891\n",
      "iteration (10350): loss = 0.472, accuracy = 0.844\n",
      "iteration (10400): loss = 0.637, accuracy = 0.797\n",
      "iteration (10450): loss = 0.439, accuracy = 0.891\n",
      "iteration (10500): loss = 0.390, accuracy = 0.859\n",
      "iteration (10550): loss = 0.593, accuracy = 0.812\n",
      "iteration (10600): loss = 0.486, accuracy = 0.766\n",
      "iteration (10650): loss = 0.290, accuracy = 0.891\n",
      "iteration (10700): loss = 0.484, accuracy = 0.812\n",
      "validation for epoch 13\n",
      "-  epoch 13: validation accuracy = 0.751\n",
      "train for epoch 14\n",
      "iteration (10750): loss = 0.393, accuracy = 0.844\n",
      "iteration (10800): loss = 0.388, accuracy = 0.891\n",
      "iteration (10850): loss = 0.559, accuracy = 0.812\n",
      "iteration (10900): loss = 0.572, accuracy = 0.797\n",
      "iteration (10950): loss = 0.385, accuracy = 0.859\n",
      "iteration (11000): loss = 0.667, accuracy = 0.766\n",
      "iteration (11050): loss = 0.502, accuracy = 0.828\n",
      "iteration (11100): loss = 0.370, accuracy = 0.938\n",
      "iteration (11150): loss = 0.411, accuracy = 0.812\n",
      "iteration (11200): loss = 0.584, accuracy = 0.766\n",
      "iteration (11250): loss = 0.389, accuracy = 0.875\n",
      "iteration (11300): loss = 0.650, accuracy = 0.766\n",
      "iteration (11350): loss = 0.517, accuracy = 0.781\n",
      "iteration (11400): loss = 0.430, accuracy = 0.812\n",
      "iteration (11450): loss = 0.416, accuracy = 0.812\n",
      "validation for epoch 14\n",
      "-  epoch 14: validation accuracy = 0.750\n",
      "train for epoch 15\n",
      "iteration (11500): loss = 0.594, accuracy = 0.812\n",
      "iteration (11550): loss = 0.604, accuracy = 0.797\n",
      "iteration (11600): loss = 0.424, accuracy = 0.844\n",
      "iteration (11650): loss = 0.439, accuracy = 0.844\n",
      "iteration (11700): loss = 0.475, accuracy = 0.844\n",
      "iteration (11750): loss = 0.395, accuracy = 0.938\n",
      "iteration (11800): loss = 0.443, accuracy = 0.828\n",
      "iteration (11850): loss = 0.431, accuracy = 0.828\n",
      "iteration (11900): loss = 0.489, accuracy = 0.812\n",
      "iteration (11950): loss = 0.487, accuracy = 0.828\n",
      "iteration (12000): loss = 0.761, accuracy = 0.703\n",
      "iteration (12050): loss = 0.378, accuracy = 0.891\n",
      "iteration (12100): loss = 0.487, accuracy = 0.734\n",
      "iteration (12150): loss = 0.621, accuracy = 0.797\n",
      "iteration (12200): loss = 0.416, accuracy = 0.812\n",
      "validation for epoch 15\n",
      "-  epoch 15: validation accuracy = 0.748\n",
      "train for epoch 16\n",
      "iteration (12250): loss = 0.701, accuracy = 0.766\n",
      "iteration (12300): loss = 0.534, accuracy = 0.812\n",
      "iteration (12350): loss = 0.715, accuracy = 0.766\n",
      "iteration (12400): loss = 0.448, accuracy = 0.859\n",
      "iteration (12450): loss = 0.427, accuracy = 0.844\n",
      "iteration (12500): loss = 0.430, accuracy = 0.844\n",
      "iteration (12550): loss = 0.589, accuracy = 0.797\n",
      "iteration (12600): loss = 0.625, accuracy = 0.781\n",
      "iteration (12650): loss = 0.584, accuracy = 0.766\n",
      "iteration (12700): loss = 0.467, accuracy = 0.875\n",
      "iteration (12750): loss = 0.466, accuracy = 0.844\n",
      "iteration (12800): loss = 0.418, accuracy = 0.828\n",
      "iteration (12850): loss = 0.583, accuracy = 0.781\n",
      "iteration (12900): loss = 0.272, accuracy = 0.922\n",
      "iteration (12950): loss = 0.372, accuracy = 0.891\n",
      "iteration (13000): loss = 0.433, accuracy = 0.859\n",
      "validation for epoch 16\n",
      "-  epoch 16: validation accuracy = 0.750\n",
      "train for epoch 17\n",
      "iteration (13050): loss = 0.431, accuracy = 0.844\n",
      "iteration (13100): loss = 0.596, accuracy = 0.750\n",
      "iteration (13150): loss = 0.425, accuracy = 0.812\n",
      "iteration (13200): loss = 0.509, accuracy = 0.828\n",
      "iteration (13250): loss = 0.724, accuracy = 0.719\n",
      "iteration (13300): loss = 0.422, accuracy = 0.859\n",
      "iteration (13350): loss = 0.557, accuracy = 0.750\n",
      "iteration (13400): loss = 0.428, accuracy = 0.875\n",
      "iteration (13450): loss = 0.541, accuracy = 0.797\n",
      "iteration (13500): loss = 0.457, accuracy = 0.812\n",
      "iteration (13550): loss = 0.375, accuracy = 0.828\n",
      "iteration (13600): loss = 0.498, accuracy = 0.797\n",
      "iteration (13650): loss = 0.485, accuracy = 0.859\n",
      "iteration (13700): loss = 0.471, accuracy = 0.828\n",
      "iteration (13750): loss = 0.502, accuracy = 0.797\n",
      "validation for epoch 17\n",
      "-  epoch 17: validation accuracy = 0.748\n",
      "train for epoch 18\n",
      "iteration (13800): loss = 0.517, accuracy = 0.828\n",
      "iteration (13850): loss = 0.511, accuracy = 0.812\n",
      "iteration (13900): loss = 0.389, accuracy = 0.906\n",
      "iteration (13950): loss = 0.440, accuracy = 0.781\n",
      "iteration (14000): loss = 0.354, accuracy = 0.875\n",
      "iteration (14050): loss = 0.378, accuracy = 0.891\n",
      "iteration (14100): loss = 0.362, accuracy = 0.875\n",
      "iteration (14150): loss = 0.605, accuracy = 0.812\n",
      "iteration (14200): loss = 0.532, accuracy = 0.859\n",
      "iteration (14250): loss = 0.634, accuracy = 0.734\n",
      "iteration (14300): loss = 0.644, accuracy = 0.734\n",
      "iteration (14350): loss = 0.614, accuracy = 0.766\n",
      "iteration (14400): loss = 0.604, accuracy = 0.781\n",
      "iteration (14450): loss = 0.612, accuracy = 0.766\n",
      "iteration (14500): loss = 0.354, accuracy = 0.875\n",
      "validation for epoch 18\n",
      "-  epoch 18: validation accuracy = 0.749\n",
      "train for epoch 19\n",
      "iteration (14550): loss = 0.345, accuracy = 0.875\n",
      "iteration (14600): loss = 0.435, accuracy = 0.875\n",
      "iteration (14650): loss = 0.505, accuracy = 0.844\n",
      "iteration (14700): loss = 0.566, accuracy = 0.844\n",
      "iteration (14750): loss = 0.524, accuracy = 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration (14800): loss = 0.450, accuracy = 0.828\n",
      "iteration (14850): loss = 0.615, accuracy = 0.766\n",
      "iteration (14900): loss = 0.523, accuracy = 0.844\n",
      "iteration (14950): loss = 0.405, accuracy = 0.844\n",
      "iteration (15000): loss = 0.402, accuracy = 0.844\n",
      "iteration (15050): loss = 0.581, accuracy = 0.781\n",
      "iteration (15100): loss = 0.450, accuracy = 0.844\n",
      "iteration (15150): loss = 0.499, accuracy = 0.812\n",
      "iteration (15200): loss = 0.444, accuracy = 0.828\n",
      "iteration (15250): loss = 0.421, accuracy = 0.859\n",
      "validation for epoch 19\n",
      "-  epoch 19: validation accuracy = 0.749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.745\n",
      "Model saved in lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = YourModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        # Save your model\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "conv3 layer: (?, 4, 4, 128)\n",
      "conv4 layer: (?, 2, 2, 256)\n",
      "flat layer: (?, 1024)\n",
      "fc3 layer: (?, 100)\n",
      "fc4 layer: (?, 100)\n",
      "fc5 layer: (?, 10)\n",
      "INFO:tensorflow:Restoring parameters from lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load your model\n",
    "model = YourModel()\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_assignment",
   "language": "python",
   "name": "virtual_assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
